%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%									Introduction									%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Introduction}
\pagenumbering{arabic}
 
\addstarredchapter{Introduction}
%	\epigraph{\og Une super citation, si vous êtes inspiré d'entrée de jeu. \fg{}}{D. Depriester}
\markboth{INTRODUCTION}{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% Début du chapitre
%\section*{Avant-propos}

Ce travail a été réalisé dans le cadre d\rq{}une thèse convention CIFRE, issue d\rq{}un partenariat entre la compagnie d\rq{}assurance AXA et Aix-Marseille Université. Il comprend une partie recherche opérationelle concrétisée par un projet de recherche et développement au sein d\rq{}AXA France et une partie recherche académique visant à l\rq{}élaboration de méthodes numériques pour la gestion des risques des compagnies d\rq{}assurance. \\

La partie recherche opérationelle de ce travail s\rq{}inscrit dans les préparatifs de l\rq{}entrée en vigueur de la directive européenne Solvabilité II. Cette directive définit un nouveau cadre prudentiel et oblige les compagnies d\rq{}assurance européennes à adopter une vue prospective de leurs engagements afin de bien définir leur niveau de provisionnement. Ayant été accueilli au sein d\rq{}une direction technique en charge de la gestion des contrats d\rq{}assurance vie du périmètre épargne individuelle, le projet de recherche et développement conduit au sein d\rq{}AXA France a eu pour but l\rq{}optimisation des temps de calcul des provisions \textit{Best Estimate} associées aux contrats d\rq{}assurance vie de type épargne individuelle. L\rq{}assuré, lors de la souscription, effectue un premier versement pour constituer un capital initial. Ce capital est investi sur différents supports d\rq{}investissement dont la performance influence la valeur de l\rq{}épargne au cours du temps. L\rq{}assureur s\rq{}engage à verser à l\rq{}assuré ou à ses bénéficiaires désignés la valeur de l\rq{}épargne en cas de décès ou de rachat du contrat. Le rachat du contrat est une action volontaire de l\rq{}assuré qui décide de récupérer tout ou partie de son épargne afin de l\rq{}utiliser autrement. La provision \textit{Best Estimate} d\rq{}un contrat épargne est égale à la moyenne des \textit{cash-flows} sortants, actualisés et pondérés par leur probabilité d\rq{}occurence au cours du temps. Le décès et le rachat sont les deux évènements qui entrainent un \textit{cash-flow} sortant. Ces deux évènements sont respectivement associés à des probabilités de décès et de rachat fonction de l\rq{}âge de l\rq{}assuré, de son genre et aussi de l\rq{}ancienneté du contrat. Des lois de rachat et de décès sont calibrées statistiquement à l\rq{}aide d\rq{}un historique. La valeur du \textit{cash-flow} sortant est fonction de la valeur de l\rq{}épargne au cours du temps et du rendement des actifs sur les marchés financiers. Le rendement des actifs est modélisé par l\rq{}intermédiaire de processus stochastiques. Des scénarios d\rq{}évolution de taux d\rq{}intérêts sont générés sur la base de ces processus stochastiques. La provision est évaluée pour chacun de ces scénarios, la moyenne des provisions sur les différents scénarios financiers renvoit la provision \textit{Best Estimate}. La directive Solvabilité II préconise une approche contrat par contrat. Le temps de calcul pour un contrat est relativement faible, de l\rq{}ordre de quelques secondes, il devient problématique dans le cadre d\rq{}un portefeuille de contrats volumineux comme celui d\rq{}AXA France qui comprend $3$ millions de contrats. L\rq{}autre problème réside dans la consommation de mémoire induite par le stockage des données de simulation. Les autorités de contrôle et de réglementation sont conscientes de ces problèmes et cautionnent la mise en place de techniques pour réduire les temps de calculs sous réserve de ne pas fausser significativement la valorisation des provisions.  L'objectif du projet de recherche et développement mené au cours de cette thèse est la mise au point d'une procédure visant à agréger le portefeuille de contrats d\rq{}assurance vie. Le portefeuille de contrats agrégé est alors utilisé en \textit{input} du modèle interne de projection des \textit{cash-flows} permetant l'évaluation des provisions \textit{Best Estimate}.\\

La partie recherche académique de ce travail consiste en la mise au point d\rq{}une méthode numérique d\rq{}approximation des probabilités dans le cadre des modèles de risque en assurance non-vie. Pour un portefeuille de contrats d\rq{}assurance non vie, sur une période d\rq{}exercice donnée, le nombre de sinistres est une variable aléatoire de comptage et le montant des sinistres est une variable aléatoire positive. La charge totale du portefeuille, qui correspond au cumul des prestations à verser par l\rq{}assureur sur la période d\rq{}exercice considérée, est une quantité centrale dans la gestion des risques de la compagnie. Elle quantifie les engagements contractés par la compagnie d\rq{}assurance auprès de ses clients. Pour calibrer le montant de la prime et déterminer les marges de solvabilité, l\rq{}actuaire doit étudier la distribution du cumul des prestations et connaître son espérance, sa variance, sa fonction de survie ou encore ses quantiles. La charge totale du portefeuille admet une distribution de probabilité composée. Le problème de ces distributions de probabilité est que leur densité de probabilité n\rq{}est accessible que dans un nombre très restreint de cas. Les calculs de probabilité peuvent être effectués par le biais de méthodes de simulation de Monte-Carlo mais les temps de calcul importants associés à une bonne précision sont souvent prohibitifs et motivent la mise au point de méthodes numériques d\rq{}approximation de la densité de probabilité. Une compagnie d\rq{}assurance possède souvent plusieurs branches d\rq{}activité, chaque branche d\rq{}activité est associée à une charge totale et la gestion globale des risques implique la définition d\rq{}un vecteur aléatoire. En cas d\rq{}indépendance entre les branches d\rq{}activité, le problème se résume à considérer plusieurs problèmes en dimension $1$. En revanche, s\rq{}il existe une corrélation entre les branches d\rq{}activité alors il est opportun de modéliser les charges totales conjointement via un vecteur aléatoire associé à une distribution de probabilité multivariée. Les méthodes numériques doivent alors pouvoir être étendues en dimension supérieure à $1$. Cette corrélation est particulièrement pertinente dans la gestion des risques d\rq{}un réassureur qui réassure la même branche d\rq{}activité de plusieurs compagnies d\rq{}assurance. Un prolongement du modèle collectif est étudié en théorie de la ruine où un aspect dynamique est ajouté. La théorie de la ruine concerne la modélisation de la richesse globale d'une compagnie d'assurance ou la réserve financière allouée à une certaine branche d'activité ou portefeuille de contrats. La réserve financière est égale à une réserve initiale à laquelle s'ajoute les primes reçues par unité de temps moins les prestations. L'arrivée des sinistres est modélisée par un processus de comptage, le montant des prestations par des variables aléatoires positives. L'objectif est de déterminer la probabilité de ruine qui correspond a la probabilité de passage en dessous de $0$ du processus en fonction de la réserve financière initiale. La complexité des variables aléatoires en jeu rend la probabilité de ruine difficile à évaluer via des formules fermées d'où la mise au point de méthodes numériques.\\

L'objet de ce travail est d'optimiser la précision et la rapidité des temps de calcul. La partie recherche opérationnelle traite d\rq{}une procédure à utiliser en amont du calcul alors que la partie recherche académique s\rq{}intéresse à la façon même de réaliser les calculs.\\

Le Chapitre \ref{Chapter1} présente les distributions composées et leur utilité en actuariat, et en théorie de la ruine. La distribution composée en dimension $1$ modélise le cumul du montant des prestations pour un portefeuille de contrats sur une période d'exercice donnée. Le concept de distribution composée s\rq{}étend en dimension supérieure à $1$ pour permettre la modélisation jointe des risques supportés par plusieurs portefeuilles dont les charges totales sont corrélées. Le Chapitre \ref{Chapter1} s'achève sur une introduction à la théorie de la ruine avec la présentation du modèle de ruine de Poisson composé et la définition de la probabilité de ruine ultime.\\

Le Chapitre \ref{Chapter2} présente la méthode numérique d'approximation au centre de ce travail et comprend la plupart des résultats mathématiques de cette thèse. La densité de probabilité d\rq{}une variable aléatoire est projetée sur une base de polynômes orthogonaux. L\rq{}approximation est obtenue en tronquant à un certain ordre la représentation polynomiale de la densité de probabilité. La \gls{fdr} et la \gls{fds} sont approchées par intégration de l\rq{}approximation polynomiale de la densité de probabilité. L\rq{}application de la méthode d\rq{}approximation aux distributions composées en dimension $1$ conduit à opter pour une mesure de probabilité gamma associée aux polynômes de Laguerre généralisés. Pour que l\rq{}approximation polynomiale soit valide, il est nécessaire de vérifier une condition d\rq{}intégrabilité. La Proposition \ref{BoundUnivariateTheorem} définit une majoration de la densité de probabilité qui permet de choisir les paramètres de la mesure de référence, voir Corollaire \ref{CorrolaryParameterChoiceUnivariate}, pour assurer la validité de l\rq{}approximation polynomiale. La qualité de l\rq{}approximation dépend de la décroissance des coefficients de la représentation polynomiale. La Proposition \ref{OrdreCoefficient} indique une convergence en $1/k$, sous certaines conditions de régularité sur la densité de probabilité. La fonction génératrice des coefficients s\rq{}exprime en fonction de la transformée de Laplace de la densité de probabilité. L\rq{}étude de la forme de cette fonction génératrice permet dans certains cas de choisir les paramètres de la mesure de référence pour accélérer la convergence vers $0$ des coefficients. L\rq{}approximation de fonctions basées sur des polynômes ou des fonctions orthogonales est un sujet déjà beaucoup étudié dans la litterature, la plus-value de ce travail réside en grande partie dans les façons de choisir les paramètres de la mesure de référence pour obtenir une meilleure approximation. La densité de probabilité multivariée d\rq{}un vecteur aléatoire peut aussi être projetée sur une base de polynômes orthogonaux. Ces polynômes sont orthogonaux par rapport à une mesure de référence construite via le produit de mesures de probabilité univariées appartenant aux \gls{fenq}. La représentation polynomiale de la densité de probabilité multivariée est justifiée par le Théorème \ref{MultivariatePolynomialExpansion}. L\rq{}approximation polynomiale découle d\rq{}une troncature des séries infinies qui définissent la représentation polynomiale. La \gls{fdrm} et la \gls{fdsm} sont obtenues par intégration de l\rq{}approximation polynomiale. L\rq{}application de la méthode d\rq{}aproximation aux distributions composées multivariées conduisent à opter pour des mesures de références gamma et des polynômes multivariés issus du produit de polynômes de Laguerre généralisés respectivement orthogonaux par rapport aux mesures de probabilité marginales choisies. La Proposition \ref{BoundMultivariateTheorem} propose une majoration de la densité de probabilité multivariée. Le choix des paramètres des mesures de référence gamma est effectué conformément au Corollaire \ref{ParameterChoiceMultivariateCorrolary} de façon à satisfaire la condition d\rq{}intégrabilité qui sous-tend la validité de la représentation polynomiale. Le choix des paramètres est affiné via l\rq{}étude de la fonction génératrice des coefficients qui s\rq{}exprime en fonction de la transformée Laplace du vecteur aléatoire considéré. La représentation polynomiale en dimension $2$ est reliée aux lois de probabilité de Lancaster. Le vecteur aléatoire introduit dans la Définition \ref{GoffardBivariateExponentialDistributionDef} admet une distribution particulière sur $\mathbb{R}_{+}^{2}$. La Proposition \ref{GoffardBivariateExponentialDistributionFgmmProp} établit l\rq{}appartenance de cette distribution aux lois de Lancaster de type gamma-gamma. Une illustration numérique des performances de la méthode d\rq{}approximation polynomiale sur l\rq{}approximation d\rq{}une distribution Poisson composée est proposée et une étude comparative avec les autres méthodes numériques évoquées dans ce travail est conduite. En plus de l\rq{}approximation de la densité de probabilité et de la \gls{fds}, une approximation polynomiale de la prime \textit{stop-loss} usuelle est étudiée. Le Chapitre \ref{Chapter2} s\rq{}achève sur la description de l\rq{}estimateur de la densité de probabilité basé sur la formule d\rq{}approximation polynomiale. Une discussion autour de son application concrète à l\rq{}estimation des distributions composées en fonction des données disponibles conclut le Chapitre \ref{Chapter2}.\\

Le Chapitre \ref{Chapter4} présente l\rq{}application de la méthode d\rq{}approximation via la représentation polynomiale à l\rq{}évaluation de la probabilité de ruine ultime dans le modèle de ruine de Poisson composé. Une comparaison avec d\rq{}autres méthodes numériques d\rq{}approximation est effectuée. Le Chapitre \ref{Chapter4} est un article scientifique accepté, \citet{GoLoPo15a}.\\

Le Chapitre \ref{Chapter5} présente l\rq{}application de la méthode d\rq{}approximation via la représentation polynomiale à l\rq{}évaluation des probabilités associées à une distribution composée bivariée. L\rq{}usage de telles distributions en actuariat et plus particulièrement en réassurance est justifié. Une comparaison avec d\rq{}autres méthodes numériques d\rq{}approximation est également effectuée. Le Chapitre \ref{Chapter5} est un article scientifique soumis, \citet{GoLoPo15b}.\\

Le Chapitre \ref{Chapter6} décrit la procédure d\rq{}agrégation des portefeuilles de contrat d\rq{}assurance vie de type épargne. Il s\rq{}agit d\rq{}une procédure en deux étapes, comprenant une classification des contrats en portefeuille via des algorithmes de classification classiques en analyse de données, suivie de la détermination d\rq{}un contrat représentatif, appelé \textit{model point}, pour chacune des classes. Le portefeuille de contrats agrégé est utilisé comme input du modèle interne de projection des \textit{cash-flows}. Le Chapitre \ref{Chapter6} est un article scientifique accepté, \citet{GoGu15}.  

\renewcommand{\bibsection}{\section*{Mes Publications}}
\bibliographystyle{francaissc}
\bibliography{MesPublications}
  